{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedHanzala/AI-Assisted-Document-Scanner/blob/main/notebooks/dataset_preperation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "Dataset Preperation\n",
        "</h1>\n",
        "<p>This is the code used for preparing the datasets. There is alot of hard-coded paths added in the code, if you want to use this code you might have to do some editing. ill make this more general if i get time ;) </p>"
      ],
      "metadata": {
        "id": "0qgqIbHtrKQo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBAdeVYJCjEm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "!pip install pydub\n",
        "!pip install yt-dlp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Downloading videos from youtube\n",
        "</h2>"
      ],
      "metadata": {
        "id": "WRuN5Vpfrql2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olpY3KkB1wAz"
      },
      "outputs": [],
      "source": [
        "#download video from youtube\n",
        "!yt-dlp https://www.youtube.com/watch?v=L8LndKrrsOE&ab_channel=AskGanjiswag\n",
        "\n",
        "\n",
        "!yt-dlp https://www.youtube.com/watch?v=jXO1-OWBWHo&ab_channel=AskGanjiswag\n",
        "\n",
        "!yt-dlp https://www.youtube.com/watch?v=d5Ce3xFX0NQ&ab_channel=AskGanjiswag\n",
        "!yt-dlp https://www.youtube.com/watch?v=rRFA2OF9ZO4&ab_channel=AskGanjiswag\n",
        "!yt-dlp https://www.youtube.com/watch?v=3vOMenk3Yp4&ab_channel=AskGanjiswag\n",
        "\n",
        "!yt-dlp https://www.youtube.com/watch?v=l8Y5qwGyLy8&ab_channel=AskGanjiswag\n",
        "\n",
        "!yt-dlp https://www.youtube.com/watch?v=Ly4Tvwl8OQA\n",
        "\n",
        "!yt-dlp https://www.youtube.com/watch?v=Dw-ZrwcPrH4\n",
        "\n",
        "!yt-dlp https://www.youtube.com/watch?v=9NK5i6u1rxo&ab_channel=AskGanjiswag\n",
        "\n",
        "!yt-dlp https://www.youtube.com/watch?v=PYw4py-ykso&ab_channel=AskGanjiswag\n",
        "!yt-dlp https://www.youtube.com/watch?v=FFZxsVaoE7w&ab_channel=AskGanjiswag\n",
        "\n",
        "!yt-dlp https://www.youtube.com/watch?v=K4FKdoQXSsM\n",
        "!yt-dlp https://www.youtube.com/watch?v=Dw-ZrwcPrH4\n",
        "!yt-dlp https://www.youtube.com/watch?v=0P3WBPwbKbU\n",
        "!yt-dlp https://www.youtube.com/watch?v=oByiu1TVWWI\n",
        "!yt-dlp https://www.youtube.com/watch?v=mclKOoczZm0\n",
        "!yt-dlp https://www.youtube.com/watch?v=DXYuCrT4YsA\n",
        "!yt-dlp https://www.youtube.com/watch?v=JQo3-g1hImQ&ab_channel=AskGanjiswag\n",
        "!yt-dlp https://www.youtube.com/watch?v=FDOm7GLnNmw&ab_channel=AskGanjiswag\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Renaming the videos as 1,2,..,n</h2>"
      ],
      "metadata": {
        "id": "Jm8vSsvAr0nO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMUXAbs3L36j"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "directory = \"/content\"\n",
        "extension = \".webm\"\n",
        "\n",
        "# Get the list of files in the directory\n",
        "file_list = os.listdir(directory)\n",
        "print(file_list)\n",
        "\n",
        "# Sort the files in alphanumeric order\n",
        "file_list.sort()\n",
        "\n",
        "# Rename the files from 1 to 19\n",
        "for i, filename in enumerate(file_list[:19], start=1):\n",
        "    if filename.endswith(extension):\n",
        "        new_filename = str(i) + extension\n",
        "        current_path = os.path.join(directory, filename)\n",
        "        new_path = os.path.join(directory, new_filename)\n",
        "        os.rename(current_path, new_path)\n",
        "        print(f\"Renamed {filename} to {new_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Converting into wav files</h2>"
      ],
      "metadata": {
        "id": "2-7wVGLNsDnW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqBHOspq3SPD"
      },
      "outputs": [],
      "source": [
        "#change to wav format\n",
        "from pydub import AudioSegment\n",
        "import subprocess\n",
        "\n",
        "for i in range(18):\n",
        "  # Load the WebM video file\n",
        "  video_file = f\"{i+1}.webm\"\n",
        "\n",
        "  # Extract the audio from the video and save it as a temporary file\n",
        "  temp_file = \"temp_audio.wav\"\n",
        "  subprocess.call(['ffmpeg', '-i', video_file, '-vn', '-acodec', 'pcm_s16le', '-ar', '44100', '-ac', '2', temp_file])\n",
        "\n",
        "  # Load the audio from the temporary file\n",
        "  audio = AudioSegment.from_file(temp_file, format=\"wav\")\n",
        "\n",
        "  # Export the audio as a new WAV file\n",
        "  audio.export(f\"output_file{i+1}.wav\", format=\"wav\")\n",
        "\n",
        "  # Delete the temporary file\n",
        "  subprocess.call(['rm', temp_file])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFjnM31ZenYO"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(filename='output_file.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Converting from 44k to 22k Hz</h2>"
      ],
      "metadata": {
        "id": "gI970_9_sIMN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pc3tS5iQs5Em"
      },
      "outputs": [],
      "source": [
        "#convert to 22kHz sampling rate\n",
        "from pydub import AudioSegment\n",
        "\n",
        "for i in range(18):\n",
        "  # Load the audio file\n",
        "  audio = AudioSegment.from_wav(f\"output_file{i+1}.wav\")\n",
        "\n",
        "  # Set the new sample rate\n",
        "  new_sample_rate = 22050\n",
        "\n",
        "  # Change the sample rate\n",
        "  audio = audio.set_frame_rate(new_sample_rate)\n",
        "\n",
        "  # Export the audio file with the new sample rate\n",
        "  audio.export(f\"output_file{i+1}.wav\", format=\"wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Splitting the wav into chunks on silence</h2>"
      ],
      "metadata": {
        "id": "y0F-HmMRsUjk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rbvf-ap_Cmva"
      },
      "outputs": [],
      "source": [
        "#splitting into chunks\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "audio_chunks = []\n",
        "for i in range(18):\n",
        "  #reading from audio mp3 file\n",
        "  path=f\"output_file{i+1}.wav\"\n",
        "  sound = AudioSegment.from_wav(path)\n",
        "  # spliting audio files\n",
        "  print(f\"splitting {path}\")\n",
        "  print(len(audio_chunks))\n",
        "  x = split_on_silence(sound, min_silence_len=500, silence_thresh=-40 )\n",
        "  audio_chunks.append(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZoQrxrfMWQx"
      },
      "outputs": [],
      "source": [
        "output_path=\"/content/drive/MyDrive/junaid-akram-dataset/wavs/\"\n",
        "for j in range(len(audio_chunks)):\n",
        "  for i, chunk in enumerate(audio_chunks[j]):\n",
        "      # Check if the chunk has non-zero duration\n",
        "      if len(chunk) > 0:\n",
        "          # Set the output file path\n",
        "          orignal = f\"{output_path}{j}-{i}.wav\"\n",
        "          silenced_segment = AudioSegment.silent(duration=500)\n",
        "          chunk_with_silence = chunk + silenced_segment\n",
        "          # Export the audio chunk as a WAV file\n",
        "          chunk_with_silence.export(orignal, format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCzXmIUQlqlw",
        "outputId": "3d734a75-0468-44d5-fac4-1bfa96fed9c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 14078 files in the /content/drive/MyDrive/junaid-akram-dataset/wavs/ directory.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = \"/content/drive/MyDrive/junaid-akram-dataset/wavs/\"\n",
        "num_files = len(os.listdir(path))\n",
        "\n",
        "print(f\"There are {num_files} files in the {path} directory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Using Whisper AI for transcription</h1>"
      ],
      "metadata": {
        "id": "i5gbzMpisgK8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxKJb1AdCz-X"
      },
      "outputs": [],
      "source": [
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install jiwer\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import whisper\n",
        "import torchaudio\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_xSfN0lRms0",
        "outputId": "295d501c-155b-4655-a728-e53459d8f451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:30<00:00, 102MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is multilingual and has 1,541,384,960 parameters.\n"
          ]
        }
      ],
      "source": [
        "model = whisper.load_model(\"large\")\n",
        "print(\n",
        "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Transcribing into Urdu</h2>"
      ],
      "metadata": {
        "id": "8wTsPnjis5LP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38aNCbIZCgjT"
      },
      "outputs": [],
      "source": [
        "directory_path=\"/content/drive/MyDrive/junaid-akram-dataset/wavs/\"\n",
        "string=\"\"\n",
        "file_path = \"/content/drive/MyDrive/junaid-akram-dataset/transcription.txt\"\n",
        "count =0\n",
        "# Open the file in write mode and write some text to it\n",
        "\n",
        "for file_name in os.listdir(directory_path):\n",
        "  present  = False\n",
        "  if file_name != \".ipynb_checkpoints\":\n",
        "    with open(file_path, \"r\") as f:\n",
        "      # Read the contents of the file into a string\n",
        "      contents = f.read()\n",
        "      # Check if the phrase is in the contents\n",
        "      if f\"wavs/{file_name}|\" in contents:\n",
        "        present=True\n",
        "    if present == False:\n",
        "      audio = whisper.load_audio(f\"{directory_path}{file_name}\")\n",
        "      print(f\"File transcribing: {file_name}\")\n",
        "      audio = whisper.pad_or_trim(audio)\n",
        "      mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "      # detect the spoken language\n",
        "      options = whisper.DecodingOptions(language=\"ur\")\n",
        "      result = whisper.decode(model, mel, options)\n",
        "      string = f\"wavs/{file_name}|{result.text}\\n\"\n",
        "      count = count+1\n",
        "      print(count)\n",
        "      with open(file_path, \"a\") as f:\n",
        "        f.write(string)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjbZ7pneSJrl"
      },
      "outputs": [],
      "source": [
        "directory_path=\"/content/drive/MyDrive/urdu-imran-dataset/wavs/\"\n",
        "string=\"\"\n",
        "file_path = \"/content/drive/MyDrive/dataset/transcription.txt\"\n",
        "# Open the file in write mode and write some text to it\n",
        "for file_name in os.listdir(directory_path):\n",
        "  result = model.transcribe(f\"{directory_path}{file_name}\")\n",
        "  string = string+ f\"wavs/{file_name}|{result['text']}\\n\"\n",
        "\n",
        "with open(file_path, \"w\") as f:\n",
        "  f.write(string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCv5jfwEdBiW",
        "outputId": "2bffd5e8-d539-487a-fb88-ebc45454b8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of lines in train file: 2061\n",
            "Number of lines in val file: 516\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Set the file paths\n",
        "transcription_file = \"/content/drive/MyDrive/urdu-imran-dataset/transcription.txt\"\n",
        "train_file = \"/content/drive/MyDrive/urdu-imran-dataset/train.txt\"\n",
        "val_file = \"/content/drive/MyDrive/urdu-imran-dataset/val.txt\"\n",
        "\n",
        "# Set the train/val split ratio\n",
        "train_ratio = 0.8\n",
        "\n",
        "# Read the lines from the transcription file\n",
        "with open(transcription_file, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Shuffle the lines randomly\n",
        "random.shuffle(lines)\n",
        "\n",
        "# Compute the number of lines for the train and val sets\n",
        "num_train = int(train_ratio * len(lines))\n",
        "num_val = len(lines) - num_train\n",
        "\n",
        "# Write the lines to the train file\n",
        "with open(train_file, \"w\") as f:\n",
        "    f.writelines(lines[:num_train])\n",
        "\n",
        "# Write the lines to the val file\n",
        "with open(val_file, \"w\") as f:\n",
        "    f.writelines(lines[num_train:])\n",
        "\n",
        "# Print some statistics\n",
        "print(f\"Number of lines in train file: {num_train}\")\n",
        "print(f\"Number of lines in val file: {num_val}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}